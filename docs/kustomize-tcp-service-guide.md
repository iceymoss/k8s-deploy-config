# Kustomize TCP æœåŠ¡é…ç½®æŒ‡å—

**ç‰ˆæœ¬**: 1.0  
**æ—¥æœŸ**: 2025-12-25  
**é€‚ç”¨å¯¹è±¡**: DevOps å·¥ç¨‹å¸ˆã€Kubernetes ç®¡ç†å‘˜

---

## Table of Contents

1. [Project Structure Standardization](#1-project-structure-standardization)
2. [Traefik TCP Architecture and Principles](#2-traefik-tcp-architecture-and-principles)
3. [Base Layer Configuration Details](#3-base-layer-configuration-details)
4. [Overlay Layer Configuration Details](#4-overlay-layer-configuration-details)
5. [Multi-TCP Service Architecture Solutions](#5-multi-tcp-service-architecture-solutions)
6. [Best Practices](#6-best-practices)

---

## 1. Project Structure Standardization

### 1.1 Standard Directory Structure

ä¸ºäº†ä¿æŒé¡¹ç›®ç»“æ„çš„é«˜åº¦ä¸€è‡´æ€§ï¼ˆStandardizationï¼‰ï¼Œè¿™æ˜¯ GitOps çš„æœ€ä½³å®è·µã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼šä»»ä½•äººåœ¨ç»´æŠ¤é¡¹ç›®æ—¶ï¼Œçœ‹åˆ°ç›®å½•ç»“æ„å°±çŸ¥é“ï¼š`base` æ”¾é€šç”¨é…ç½®ï¼Œ`overlays` æ”¾ç¯å¢ƒå·®å¼‚åŒ–è¡¥ä¸ï¼ˆèµ„æºé™åˆ¶ã€å‰¯æœ¬æ•°ã€ç‰¹å®šè·¯ç”±è§„åˆ™ç­‰ï¼‰ã€‚

**æ ‡å‡†ç»“æ„**:
```
apps/backend/
â”œâ”€â”€ hello-api/
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â””â”€â”€ overlays/
â”‚       â””â”€â”€ development/
â”‚           â”œâ”€â”€ ingress-traefik-patch.yaml
â”‚           â”œâ”€â”€ kustomization.yaml
â”‚           â””â”€â”€ patch-resources.yaml
â””â”€â”€ tcp-demo/
    â”œâ”€â”€ base/
    â”‚   â”œâ”€â”€ deployment.yaml
    â”‚   â”œâ”€â”€ ingress-route-tcp.yaml
    â”‚   â”œâ”€â”€ kustomization.yaml
    â”‚   â””â”€â”€ service.yaml
    â””â”€â”€ overlays/
        â””â”€â”€ development/
            â”œâ”€â”€ ingress-traefik-patch.yaml
            â”œâ”€â”€ kustomization.yaml
            â””â”€â”€ patch-resources.yaml
```

### 1.2 Structure Description

- **Base å±‚**: å®šä¹‰"æ˜¯ä»€ä¹ˆ"ï¼ˆè¿™æœ‰ä¸€ä¸ª TCP è·¯ç”±ï¼‰
- **Overlay å±‚**: å®šä¹‰"æ€ä¹ˆç”¨"ï¼ˆå¼€å‘ç¯å¢ƒç”¨ mytcp å…¥å£ï¼Œæ‰“ä¸Š dev æ ‡ç­¾ï¼‰

---

## 2. Traefik TCP Architecture and Principles

Before diving into the specific YAML configurations, let's understand the overall architecture and working principles of Traefik TCP, which will help you better understand the subsequent configuration content.

### 2.1 Overall Architecture Diagram

The complete architecture of Traefik TCP services includes multiple layers, from client requests to backend Pod responses:

```mermaid
graph TB
    subgraph "External Access Layer"
        Client[ğŸ‘¤ Client<br/>nc/telnet/Application]
    end

    subgraph "Kubernetes Cluster"
        subgraph "Node Layer"
            NodePort[ğŸ”Œ NodePort:30999<br/>All nodes listening]
        end

        subgraph "Traefik Namespace"
            TraefikSvc[ğŸ”Œ Traefik Service<br/>ClusterIP]
            TraefikPod[ğŸš€ Traefik Pod<br/>Listening on 9999/tcp]
            EntryPoint[ğŸ“¥ EntryPoint: mytcp<br/>:9999/tcp]
        end

        subgraph "Routing Decision Layer"
            IngressRouteTCP[ğŸ“‹ IngressRouteTCP<br/>tcp-echo-route]
            Router[ğŸ¯ Router<br/>HostSNI: *]
        end

        subgraph "Backend Namespace"
            BackendSvc[ğŸ”Œ tcp-echo-service<br/>ClusterIP:3333]
            BackendPod1[ğŸ“¦ tcp-echo Pod 1<br/>IP: 192.168.36.102]
            BackendPod2[ğŸ“¦ tcp-echo Pod 2<br/>IP: 192.168.36.103]
        end
    end

    Client -->|1. TCP Connection<br/>NodeIP:30999| NodePort
    NodePort -->|2. Forward to Service| TraefikSvc
    TraefikSvc -->|3. Load Balance| TraefikPod
    TraefikPod -->|4. Receive Traffic| EntryPoint
    EntryPoint -->|5. Query Routing Rules| IngressRouteTCP
    IngressRouteTCP -->|6. Match Rules| Router
    Router -->|7. Find Backend Service| BackendSvc
    BackendSvc -->|8. Load Balance| BackendPod1
    BackendSvc -->|8. Load Balance| BackendPod2
    BackendPod1 -->|9. Response Data| TraefikPod
    BackendPod2 -->|9. Response Data| TraefikPod
    TraefikPod -->|10. Return Response| Client

    style Client fill:#e1f5ff
    style NodePort fill:#fff4e1
    style TraefikPod fill:#ffe1f5
    style EntryPoint fill:#ffe1f5
    style IngressRouteTCP fill:#e1ffe1
    style Router fill:#e1ffe1
    style BackendSvc fill:#fff4e1
    style BackendPod1 fill:#e1ffe1
    style BackendPod2 fill:#e1ffe1
```

### 2.2 TCP Routing Principle Diagram

The core of Traefik TCP routing lies in the matching mechanism between EntryPoint and IngressRouteTCP:

```mermaid
graph LR
    subgraph "Traefik Routing Decision Flow"
        TCP[ğŸ“¥ TCP Traffic<br/>Enter EntryPoint: mytcp]
        
        subgraph "Route Matching"
            CheckEntryPoint{Check EntryPoint<br/>Is it mytcp?}
            CheckRoute{Check Routing Rules<br/>HostSNI Match?}
            CheckService{Check Backend Service<br/>Does Service Exist?}
        end

        subgraph "Backend Selection"
            SelectPod[Select Pod<br/>Load Balance]
        end

        Success[âœ… Forward Success]
        Fail[âŒ Connection Refused]
    end

    TCP --> CheckEntryPoint
    CheckEntryPoint -->|Yes| CheckRoute
    CheckEntryPoint -->|No| Fail
    CheckRoute -->|HostSNI: *<br/>Match All| CheckService
    CheckRoute -->|No Match| Fail
    CheckService -->|Service Exists<br/>Endpoints Available| SelectPod
    CheckService -->|Service Not Found<br/>or Empty Endpoints| Fail
    SelectPod --> Success

    style TCP fill:#e1f5ff
    style CheckEntryPoint fill:#fff4e1
    style CheckRoute fill:#fff4e1
    style CheckService fill:#fff4e1
    style SelectPod fill:#e1ffe1
    style Success fill:#c8e6c9
    style Fail fill:#ffcdd2
```

**Key Points**:

1. **EntryPoint Matching**: Traefik first checks if traffic enters the correct EntryPoint (e.g., `mytcp`)
2. **Routing Rule Matching**: For pure TCP (non-TLS), must use `HostSNI('*')` to match all traffic
3. **Service Discovery**: Traefik queries Service and Endpoints through Kubernetes API
4. **Load Balancing**: If there are multiple Pods, Traefik performs load balancing

### 2.3 Data Flow Sequence Diagram

The complete TCP request-response flow is as follows:

```mermaid
sequenceDiagram
    participant Client as ğŸ‘¤ Client
    participant NodePort as ğŸ”Œ NodePort:30999
    participant TraefikSvc as ğŸ”Œ Traefik Service
    participant TraefikPod as ğŸš€ Traefik Pod
    participant K8sAPI as ğŸ§  K8s API Server
    participant IngressRouteTCP as ğŸ“‹ IngressRouteTCP
    participant BackendSvc as ğŸ”Œ Backend Service
    participant BackendPod as ğŸ“¦ Backend Pod

    Note over Client,BackendPod: Initialization Phase (When Traefik Starts)
    TraefikPod->>K8sAPI: 1. Watch IngressRouteTCP Resources
    K8sAPI-->>TraefikPod: 2. Push IngressRouteTCP Changes
    TraefikPod->>TraefikPod: 3. Parse Routing Rules<br/>EntryPoint: mytcp<br/>HostSNI: *
    TraefikPod->>K8sAPI: 4. Query Service and Endpoints
    K8sAPI-->>TraefikPod: 5. Return Backend Pod IP List
    TraefikPod->>TraefikPod: 6. Build Routing Table (In Memory)

    Note over Client,BackendPod: Request Processing Phase
    Client->>NodePort: 7. TCP Connection Request<br/>NodeIP:30999
    NodePort->>TraefikSvc: 8. Forward to Traefik Service
    TraefikSvc->>TraefikPod: 9. Load Balance to Traefik Pod
    TraefikPod->>TraefikPod: 10. Match EntryPoint: mytcp
    TraefikPod->>TraefikPod: 11. Match Routing Rules<br/>HostSNI: * (Match All)
    TraefikPod->>BackendSvc: 12. Query Service Endpoints
    BackendSvc-->>TraefikPod: 13. Return Pod IP: 192.168.36.102:3333
    TraefikPod->>BackendPod: 14. Establish TCP Connection<br/>Forward Data Stream
    BackendPod-->>TraefikPod: 15. Return Response Data
    TraefikPod-->>TraefikSvc: 16. Return Response
    TraefikSvc-->>NodePort: 17. Return Response
    NodePort-->>Client: 18. TCP Response Data
```

### 2.4 HTTP vs TCP Routing Comparison

To better understand the special nature of TCP routing, we compare the differences between HTTP and TCP routing:

```mermaid
graph TB
    subgraph "HTTP Routing (Layer 7)"
        HTTPClient[ğŸ‘¤ HTTP Client]
        HTTPTraefik[ğŸš€ Traefik]
        HTTPRouter{Routing Decision}
        HTTPRule1[Rule 1: Host=a.com]
        HTTPRule2[Rule 2: Host=b.com]
        HTTPSvc1[Service A]
        HTTPSvc2[Service B]
        
        HTTPClient -->|Host: a.com| HTTPTraefik
        HTTPTraefik --> HTTPRouter
        HTTPRouter -->|Match| HTTPRule1
        HTTPRouter -->|Match| HTTPRule2
        HTTPRule1 --> HTTPSvc1
        HTTPRule2 --> HTTPSvc2
    end

    subgraph "TCP Routing (Layer 4)"
        TCPClient[ğŸ‘¤ TCP Client]
        TCPTraefik[ğŸš€ Traefik]
        TCPEntryPoint1[EntryPoint: mytcp<br/>:9999]
        TCPEntryPoint2[EntryPoint: redis<br/>:6379]
        TCPRouter{Routing Decision<br/>HostSNI: *}
        TCPSvc1[Service A]
        TCPSvc2[Service B]
        
        TCPClient -->|Port 30999| TCPTraefik
        TCPTraefik --> TCPEntryPoint1
        TCPEntryPoint1 --> TCPRouter
        TCPRouter -->|Can Only Match One| TCPSvc1
        
        TCPClient -.->|Port 30379| TCPTraefik
        TCPTraefik -.-> TCPEntryPoint2
        TCPEntryPoint2 -.-> TCPSvc2
    end

    style HTTPClient fill:#e1f5ff
    style HTTPTraefik fill:#ffe1f5
    style HTTPRouter fill:#fff4e1
    style HTTPSvc1 fill:#e1ffe1
    style HTTPSvc2 fill:#e1ffe1
    
    style TCPClient fill:#e1f5ff
    style TCPTraefik fill:#ffe1f5
    style TCPRouter fill:#fff4e1
    style TCPSvc1 fill:#e1ffe1
    style TCPSvc2 fill:#e1ffe1
```

**Key Differences**:

| Feature | HTTP (Layer 7) | TCP (Layer 4) |
|---------|----------------|--------------|
| **Port Reuse** | âœ… Yes (via Host Header) | âŒ No (one port per service) |
| **Routing Basis** | Host Header, Path, Headers, etc. | EntryPoint (Port) |
| **Matching Rules** | Exact Match (e.g., `Host: a.com`) | Wildcard Match (`HostSNI: *`) |
| **TLS Support** | Can read SNI information | Pure TCP cannot, TLS can |
| **Service Count** | One port can serve multiple | One port can only serve one |

### 2.5 Multi-TCP Service Port Allocation Diagram

When there are multiple TCP services, each service needs an independent EntryPoint and port:

```mermaid
graph TB
    subgraph "Traefik Configuration"
        Traefik[ğŸš€ Traefik Pod]
        
        subgraph "EntryPoints"
            EP1[EntryPoint: mytcp<br/>Listen :9999/tcp]
            EP2[EntryPoint: redis<br/>Listen :6379/tcp]
            EP3[EntryPoint: mysql<br/>Listen :3306/tcp]
        end
    end

    subgraph "NodePort Mapping"
        NP1[NodePort: 30999]
        NP2[NodePort: 30379]
        NP3[NodePort: 30306]
    end

    subgraph "Backend Services"
        Svc1[tcp-echo-service<br/>:3333]
        Svc2[redis-service<br/>:6379]
        Svc3[mysql-service<br/>:3306]
    end

    NP1 -->|Map to| EP1
    NP2 -->|Map to| EP2
    NP3 -->|Map to| EP3

    EP1 -->|Route to| Svc1
    EP2 -->|Route to| Svc2
    EP3 -->|Route to| Svc3

    style Traefik fill:#ffe1f5
    style EP1 fill:#fff4e1
    style EP2 fill:#fff4e1
    style EP3 fill:#fff4e1
    style NP1 fill:#e1f5ff
    style NP2 fill:#e1f5ff
    style NP3 fill:#e1f5ff
    style Svc1 fill:#e1ffe1
    style Svc2 fill:#e1ffe1
    style Svc3 fill:#e1ffe1
```

**Port Allocation Logic**:

1. **NodePort**: External access port (e.g., 30999)
2. **EntryPoint**: Internal listening port in Traefik (e.g., 9999)
3. **Service Port**: Backend service port (e.g., 3333)

Each TCP service needs such an independent port mapping.

---

## 3. Base Layer Configuration Details

### 3.1 Deployment Configuration

**File**: `apps/backend/tcp-demo/base/deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tcp-echo-demo
  namespace: backend
  labels:
    app: tcp-echo
spec:
  # [å‰¯æœ¬æ•°]
  # è¿™æ˜¯ Base çš„é»˜è®¤å€¼ã€‚
  # åœ¨ overlays/development/patch-resources.yaml ä¸­ï¼Œæˆ‘ä»¬ä¼šæŠŠå®ƒè¦†ç›–ä¸º 1ã€‚
  # åœ¨ç”Ÿäº§ç¯å¢ƒå¯èƒ½ä¿ç•™è¿™ä¸ª 10 æˆ–è€…è®¾ç½®æ›´å¤šã€‚
  replicas: 10

  selector:
    matchLabels:
      app: tcp-echo # å¿…é¡»åŒ¹é… template é‡Œçš„æ ‡ç­¾

  template:
    metadata:
      labels:
        app: tcp-echo # å¿…é¡»åŒ¹é… Service çš„ selector
    spec:
      containers:
        - name: proxy
          # [æ ¸å¿ƒæŠ€å·§ï¼šé•œåƒå ä½ç¬¦]
          # è¿™é‡Œå†™çš„ä¸æ˜¯çœŸå®çš„é•œåƒåœ°å€ï¼Œè€Œæ˜¯ä¸€ä¸ªé€»è¾‘åç§°ã€‚
          # çœŸå®çš„é•œåƒåœ°å€ (newName) å’Œç‰ˆæœ¬ (newTag) ä¼šåœ¨ overlays/*/kustomization.yaml ä¸­
          # é€šè¿‡ 'images' å­—æ®µåŠ¨æ€æ›¿æ¢ã€‚
          # å¥½å¤„ï¼šBase æ–‡ä»¶ä¸å…·ä½“é•œåƒä»“åº“è§£è€¦ã€‚
          image: tcp-echo-server

          ports:
            - containerPort: 3333 # å®¹å™¨åº”ç”¨å®é™…ç›‘å¬çš„ç«¯å£
```

**å…³é”®ç‚¹**:
- **é•œåƒå ä½ç¬¦**: `image: tcp-echo-server` ä¸æ˜¯çœŸå®é•œåƒï¼Œè€Œæ˜¯é€»è¾‘åç§°
- **æ ‡ç­¾åŒ¹é…**: Deployment çš„ selector å’Œ template labels å¿…é¡»ä¸€è‡´
- **è§£è€¦è®¾è®¡**: Base å±‚ä¸ä¾èµ–å…·ä½“é•œåƒä»“åº“

---

### 3.2 Service Configuration

**File**: `apps/backend/tcp-demo/base/service.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: tcp-echo-service
  namespace: backend
spec:
  # [æœåŠ¡ç±»å‹]
  # è¿™é‡Œçœç•¥äº† type å­—æ®µï¼Œé»˜è®¤æ˜¯ ClusterIPã€‚
  # æ„å‘³ç€è¿™ä¸ª Service åªèƒ½åœ¨é›†ç¾¤å†…éƒ¨è®¿é—®ï¼Œå¤–éƒ¨è®¿é—®å¿…é¡»é€šè¿‡ Traefik Ingressã€‚

  ports:
    - port: 3333        # [é›†ç¾¤å†…ç«¯å£] Service åœ¨ ClusterIP ä¸Šç›‘å¬çš„ç«¯å£ (Traefik è®¿é—®è¿™ä¸ª)
      targetPort: 3333  # [å®¹å™¨ç«¯å£] æµé‡è½¬å‘ç»™ Pod é‡Œå®¹å™¨å®é™…ç›‘å¬çš„ç«¯å£
      name: tcp         # ç«¯å£å‘½åï¼Œå¥½ä¹ æƒ¯ï¼Œæ–¹ä¾¿å¼•ç”¨

  # [æ ‡ç­¾é€‰æ‹©å™¨]
  # åªæœ‰å¸¦æœ‰ app=tcp-echo æ ‡ç­¾çš„ Pod æ‰ä¼šæˆä¸ºè¿™ä¸ª Service çš„åç«¯ã€‚
  selector:
    app: tcp-echo
```

**ç«¯å£æ˜ å°„è¯´æ˜**:
- `port`: Service åœ¨é›†ç¾¤å†…çš„ç«¯å£ï¼ˆTraefik è®¿é—®è¿™ä¸ªï¼‰
- `targetPort`: Pod å®¹å™¨å®é™…ç›‘å¬çš„ç«¯å£
- `name`: ç«¯å£åç§°ï¼Œä¾¿äºå¼•ç”¨

---

### 3.3 IngressRouteTCP Configuration

**File**: `apps/backend/tcp-demo/base/ingress-route-tcp.yaml`

```yaml
apiVersion: traefik.io/v1alpha1
kind: IngressRouteTCP # æ³¨æ„ï¼šè¿™æ˜¯ Traefik ä¸“ç”¨çš„ CRDï¼Œä¸“é—¨å¤„ç† TCP æµé‡
metadata:
  name: tcp-echo-route
  namespace: backend
spec:
  # [å…¥å£ç‚¹ç»‘å®š]
  # å¿…é¡»å¯¹åº” Traefik å¯åŠ¨å‚æ•° (traefik-app.yaml) ä¸­å®šä¹‰çš„ entryPointã€‚
  # æ¯”å¦‚: --entrypoints.mytcp.address=:9999/tcp
  entryPoints:
    - mytcp

  routes:
    # [è·¯ç”±åŒ¹é…è§„åˆ™]
    # HostSNI(`*`) çš„å«ä¹‰ï¼š
    # 1. å¯¹äº HTTPS (TLS)ï¼ŒTraefik å¯ä»¥è¯»å– SNI ä¿¡æ¯æ¥åŒºåˆ†åŸŸå (å¦‚ HostSNI(`example.com`))ã€‚
    # 2. å¯¹äº çº¯ TCP (é TLS)ï¼Œæ•°æ®æµæ˜¯é»‘ç›’ï¼ŒTraefik æ— æ³•çœ‹åˆ°åŸŸåä¿¡æ¯ã€‚
    # 3. å› æ­¤ï¼Œå¿…é¡»ä½¿ç”¨é€šé…ç¬¦ `*`ï¼Œè¡¨ç¤º"æ‰€æœ‰ä» mytcp ç«¯å£è¿›æ¥çš„æµé‡ï¼Œä¸ç®¡å‘ç»™è°ï¼Œéƒ½æ— è„‘è½¬å‘ç»™åç«¯"ã€‚
    - match: HostSNI(`*`)
      services:
        - name: tcp-echo-service # è½¬å‘ç»™å“ªä¸ª Service
          port: 3333             # Service çš„ç«¯å£
```

**å…³é”®ç‚¹**:
- **CRD èµ„æº**: `IngressRouteTCP` æ˜¯ Traefik è‡ªå®šä¹‰èµ„æºï¼Œä¸“é—¨å¤„ç† TCP æµé‡
- **HostSNI(`*`)**: çº¯ TCPï¼ˆé TLSï¼‰å¿…é¡»ä½¿ç”¨é€šé…ç¬¦ï¼Œå› ä¸ºæ— æ³•è¯»å–åŸŸåä¿¡æ¯
- **EntryPoint**: å¿…é¡»å¯¹åº” Traefik é…ç½®ä¸­çš„ entryPoint åç§°

---

### 3.4 Kustomization Aggregation

**File**: `apps/backend/tcp-demo/base/kustomization.yaml`

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

# [èµ„æºæ¸…å•]
# åˆ—å‡ºå½“å‰ç›®å½•ä¸‹æ‰€æœ‰éœ€è¦è¢«åŒ…å«è¿›æ¥çš„ YAML æ–‡ä»¶ã€‚
# ArgoCD æˆ–è€… 'kubectl apply -k' ä¼šè¯»å–è¿™ä¸ªåˆ—è¡¨å¹¶æŠŠå®ƒä»¬åˆå¹¶æˆä¸€ä¸ªæµã€‚
resources:
  - deployment.yaml
  - service.yaml
  - ingress-route-tcp.yaml
```

---

## 4. Overlay Layer Configuration Details

### 4.1 Resource Limit Patch

**File**: `apps/backend/tcp-demo/overlays/development/patch-resources.yaml`

```yaml
# -----------------------------------------------------------------
# æ–‡ä»¶å: apps/backend/tcp-demo/overlays/development/patch-resources.yaml
# ä½œç”¨: é’ˆå¯¹ Development ç¯å¢ƒçš„å·®å¼‚åŒ–è¡¥ä¸ (Patch)
# -----------------------------------------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  # [å…³é”®] Kustomize ä¾é è¿™ä¸ªåå­—å» base é‡Œæ‰¾"å—å®³è€…"
  # å¿…é¡»å’Œ base/deployment.yaml é‡Œçš„åå­—å®Œå…¨ä¸€è‡´
  name: tcp-echo-demo

  # æŒ‡å®šå‘½åç©ºé—´ï¼Œé€šå¸¸åœ¨ kustomization.yaml é‡Œä¹Ÿä¼šç»Ÿä¸€æŒ‡å®šï¼Œè¿™é‡Œå†™ä¸Šä¹Ÿæ— å¦¨
  namespace: backend

spec:
  # [å·®å¼‚åŒ–é…ç½®] å‰¯æœ¬æ•°
  # å¼€å‘ç¯å¢ƒä¸ºäº†çœé’±çœèµ„æºï¼Œé€šå¸¸è®¾ä¸º 1ã€‚
  # ç”Ÿäº§ç¯å¢ƒ (Production) å¯èƒ½ä¼šè®¾ä¸º 3 ä»¥å®ç°é«˜å¯ç”¨ã€‚
  replicas: 1

  template:
    spec:
      containers:
        # [å…³é”®] å®¹å™¨åå­—
        # Kustomize éœ€è¦é€šè¿‡è¿™ä¸ªåå­—çŸ¥é“ä½ è¦ä¿®æ”¹åˆ—è¡¨é‡Œçš„å“ªä¸€ä¸ªå®¹å™¨ã€‚
        # å¿…é¡»å’Œ base/deployment.yaml é‡Œçš„ container name ä¸€è‡´ (å³ "proxy")ã€‚
        - name: proxy

          # [æ ¸å¿ƒä¿®æ”¹] èµ„æºé…é¢ (Resource Quotas)
          # è¿™é€šå¸¸æ˜¯å¼€å‘ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒæœ€å¤§çš„åŒºåˆ«ä¹‹ä¸€ã€‚
          resources:

            # 1. Requests (è¯·æ±‚å€¼/ä¸‹é™)
            # å«ä¹‰ï¼šPod å¯åŠ¨æ—¶çš„"æœ€ä½æ¶ˆè´¹"ã€‚
            # ä½œç”¨ï¼šK8s è°ƒåº¦å™¨ä¼šå¯»æ‰¾å‰©ä½™èµ„æºæ»¡è¶³è¿™äº›è¦æ±‚çš„èŠ‚ç‚¹ã€‚å¦‚æœèŠ‚ç‚¹èµ„æºä¸å¤Ÿï¼ŒPod å°±ä¼š Pendingã€‚
            requests:
              # 64 Mebibytes (çº¦ç­‰äº 67MB)ã€‚
              # æ³¨æ„ï¼šMi æ˜¯äºŒè¿›åˆ¶å•ä½ (1024*1024)ï¼ŒM æ˜¯åè¿›åˆ¶å•ä½ (1000*1000)ã€‚K8s æ¨èç”¨ Miã€‚
              memory: "64Mi"

              # 50 millicores (50 æ¯«æ ¸)ï¼Œå³ 0.05 ä¸ª CPU æ ¸å¿ƒã€‚
              # 1000m = 1 æ ¸ã€‚50m æ˜¯éå¸¸å°çš„ CPU éœ€æ±‚ï¼Œé€‚åˆå¼€å‘ç¯å¢ƒé—²ç½®ã€‚
              cpu: "50m"

            # 2. Limits (é™åˆ¶å€¼/ä¸Šé™)
            # å«ä¹‰ï¼šPod è¿è¡Œæ—¶çš„"æœ€é«˜æ¶ˆè´¹"ã€‚
            # ä½œç”¨ï¼šé˜²æ­¢åº”ç”¨å†…å­˜æ³„æ¼æˆ– CPU è·‘æ­»å¾ªç¯æŠŠæ•´ä¸ªèŠ‚ç‚¹ææŒ‚ã€‚
            limits:
              # å¦‚æœå®¹å™¨ä½¿ç”¨çš„å†…å­˜è¶…è¿‡ 128Miï¼Œå®ƒä¼šè¢« OOMKilled (Out Of Memory Killed) é‡å¯ã€‚
              # è¿™é‡Œçš„é™åˆ¶æ¯”è¾ƒç´§ï¼Œå¦‚æœä½ çš„ TCP åº”ç”¨å¤„ç†å¤§é‡å¹¶å‘ï¼Œå¯èƒ½éœ€è¦è°ƒå¤§ã€‚
              memory: "128Mi"

              # å¦‚æœå®¹å™¨å°è¯•ä½¿ç”¨è¶…è¿‡ 100m (0.1 æ ¸) çš„ CPUï¼Œå®ƒä¼šè¢«æ“ä½œç³»ç»Ÿé™æµ (Throttling)ï¼Œå˜æ…¢ä½†ä¸ä¼šæ­»ã€‚
              cpu: "100m"
```

**è¡¥ä¸åŸç†**:
- è¿™ä¸æ˜¯å®Œæ•´çš„ Deploymentï¼Œè€Œæ˜¯å‘Šè¯‰ Kustomizeï¼š"æ‰¾åˆ°é‚£ä¸ªå« `tcp-echo-demo` çš„ Deploymentï¼Œåªä¿®æ”¹æˆ‘åˆ—å‡ºæ¥çš„è¿™äº›å­—æ®µï¼Œå…¶ä»–ä¿æŒåŸæ ·ã€‚"
- ä¸ºä»€ä¹ˆä¸å†™ `image` å­—æ®µï¼Ÿå› ä¸º `image` å·²ç»åœ¨ base é‡Œå®šä¹‰äº†ï¼ŒKustomize ä¼šåˆå¹¶è¿™ä¸¤ä¸ªæ–‡ä»¶ã€‚

---

### 4.2 TCP Route Patch

**File**: `apps/backend/tcp-demo/overlays/development/ingress-traefik-patch.yaml`

```yaml
# -----------------------------------------------------------------
# æ–‡ä»¶å: apps/backend/tcp-demo/overlays/development/ingress-traefik-patch.yaml
# ä½œç”¨: ä¸“é—¨ä¿®è¡¥ IngressRouteTCP çš„é…ç½®
# -----------------------------------------------------------------
# [ç±»å‹å£°æ˜]
# å¿…é¡»å®Œå…¨åŒ¹é… base æ–‡ä»¶é‡Œçš„å®šä¹‰ï¼Œå¦åˆ™ Kustomize æ‰¾ä¸åˆ°è¦ä¿®è¡¥çš„å¯¹è±¡ã€‚
apiVersion: traefik.io/v1alpha1
kind: IngressRouteTCP

metadata:
  # [å®šä½é”šç‚¹]
  # Kustomize é€šè¿‡è¿™é‡Œçš„ name çŸ¥é“ä½ è¦ä¿®æ”¹ base é‡Œçš„å“ªä¸ªèµ„æºã€‚
  name: tcp-echo-route
  namespace: backend

  # [Annotations æ³¨è§£]
  # è¿™é‡Œæ¼”ç¤ºäº†å¦‚ä½•ç»™èµ„æºæ·»åŠ é¢å¤–çš„å…ƒæ•°æ®ã€‚
  # åœºæ™¯ä¸¾ä¾‹ï¼šæœ‰äº›ç›‘æ§å·¥å…·æˆ–å¤–éƒ¨ DNS æ’ä»¶ä¾èµ– annotations æ¥å·¥ä½œã€‚
  # ä¸‹é¢è¿™ä¸€è¡Œå…¶å®æ˜¯ Traefik çš„ä¸€ç§å…ƒæ•°æ®æ ‡è®°ï¼Œæ˜ç¡®æŒ‡å‡ºè¯¥è·¯ç”±å±äº mytcp å…¥å£ç‚¹ã€‚
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: mytcp

spec:
  # [EntryPoints å…¥å£ç‚¹]
  # è¿™æ˜¯ Traefik è·¯ç”±çš„æ ¸å¿ƒã€‚
  # "mytcp" å¿…é¡»å¯¹åº”ä½ åœ¨ traefik-app.yaml (Helm values) ä¸­é…ç½®çš„
  # --entrypoints.mytcp.address=:9999/tcp
  #
  # ä¸ºä»€ä¹ˆè¦åœ¨è¡¥ä¸é‡Œå†™è¿™ä¸ªï¼Ÿ
  # 1. æ˜¾å¼å£°æ˜ï¼šå†æ¬¡ç¡®è®¤å¼€å‘ç¯å¢ƒèµ°è¿™ä¸ªå…¥å£ã€‚
  # 2. ç¯å¢ƒéš”ç¦»ï¼šå‡å¦‚ç”Ÿäº§ç¯å¢ƒçš„å…¥å£ç‚¹å« "prodtcp" (ç›‘å¬ä¸åŒç«¯å£)ï¼Œ
  #    ä½ å°±å¯ä»¥åœ¨ overlays/production é‡Œçš„è¡¥ä¸æŠŠè¿™é‡Œæ”¹æˆ "prodtcp"ã€‚
  entryPoints:
    - mytcp
```

---

### 4.3 Kustomization Master

**File**: `apps/backend/tcp-demo/overlays/development/kustomization.yaml`

```yaml
# -----------------------------------------------------------------
# æ–‡ä»¶å: apps/backend/tcp-demo/overlays/development/kustomization.yaml
# ä½œç”¨: å®šä¹‰ Development ç¯å¢ƒçš„æœ€ç»ˆå½¢æ€
# -----------------------------------------------------------------
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

# [èµ„æºå¼•ç”¨]
# è¿™é‡Œçš„ ../../base æŒ‡å‘äº†è¯¥åº”ç”¨çš„åŸºç¡€å®šä¹‰ç›®å½•ã€‚
# Kustomize ä¼šå…ˆè¯»å– base é‡Œçš„ Deployment, Service, IngressRouteTCPï¼Œ
# æŠŠå®ƒä»¬å½“ä½œ"åŸææ–™"ã€‚
resources:
  - ../../base

# [ç»Ÿä¸€æ ‡ç­¾ç®¡ç†] (Kustomize v5+ æ–°è¯­æ³•)
# ä½œç”¨ï¼šç»™å½“å‰ç¯å¢ƒä¸‹çš„æ‰€æœ‰èµ„æºï¼ˆåŒ…æ‹¬ Service çš„ selector, Deployment çš„ Pod templateï¼‰
# è‡ªåŠ¨æ‰“ä¸Šè¿™äº›æ ‡ç­¾ã€‚
# å¥½å¤„ï¼šä»¥åä½ å¯ä»¥é€šè¿‡ kubectl get all -l environment=development ä¸€é”®æŸ¥è¯¢å¼€å‘ç¯å¢ƒæ‰€æœ‰èµ„æºã€‚
labels:
  - pairs:
      environment: development
      project: ic2

# [è¡¥ä¸åˆ—è¡¨]
# è¿™æ˜¯ Kustomize æœ€å¼ºå¤§çš„åŠŸèƒ½ï¼šåœ¨ä¸ä¿®æ”¹ base æ–‡ä»¶çš„å‰æä¸‹ï¼Œä¿®æ”¹ç‰¹å®šé…ç½®ã€‚
patches:
  # 1. é’ˆå¯¹ Deployment çš„è¡¥ä¸
  # è¿™ä¸ªæ–‡ä»¶é‡Œå®šä¹‰äº† replicas: 1 å’Œ CPU/å†…å­˜é™åˆ¶ã€‚
  - path: patch-resources.yaml
    target:
      kind: Deployment
      name: tcp-echo-demo

  # 2. é’ˆå¯¹ Traefik IngressRouteTCP çš„è¡¥ä¸
  # è¿™ä¸ªæ–‡ä»¶é‡Œå®šä¹‰äº†è·¯ç”±è§„åˆ™çš„å¾®è°ƒã€‚
  - path: ingress-traefik-patch.yaml
    target:
      # [CRD å…³é”®ç‚¹ï¼ï¼ï¼]
      # å¯¹äº Kubernetes åŸç”Ÿèµ„æº (å¦‚ Deployment, Service)ï¼Œåªå†™ kind å’Œ name å°±å¤Ÿäº†ã€‚
      # ä½†æ˜¯ï¼å¯¹äº CRD (è‡ªå®šä¹‰èµ„æº)ï¼Œå¦‚ Traefik çš„ IngressRouteTCPï¼Œ
      # Kustomize æœ‰æ—¶ä¼šæ‰¾ä¸åˆ°å®ƒï¼Œæ‰€ä»¥å¿…é¡»æ˜¾å¼æŒ‡å®š group å’Œ versionã€‚
      group: traefik.io      # å¯¹åº” apiVersion çš„æ–œæ å‰éƒ¨åˆ†
      version: v1alpha1       # å¯¹åº” apiVersion çš„æ–œæ åéƒ¨åˆ†
      kind: IngressRouteTCP
      name: tcp-echo-route

# [é•œåƒæ›¿æ¢ç­–ç•¥]
# è¿™æ˜¯ Kustomize ä¸­ä¸€ç§éå¸¸é«˜çº§ä¸”ä¼˜é›…çš„ç”¨æ³•ï¼š"å ä½ç¬¦æ¨¡å¼"ï¼ˆPlaceholder Patternï¼‰ã€‚
# 
# ä¸ºä»€ä¹ˆè¿™æ ·åšå¾ˆæ£’ï¼Ÿ
# 1. è§£è€¦ (Decoupling): Base ä¸éœ€è¦çŸ¥é“çœŸå®çš„é•œåƒä»“åº“åœ°å€ï¼ˆæ¯”å¦‚æ˜¯ DockerHub è¿˜æ˜¯é˜¿é‡Œäº‘ï¼‰ã€‚
#    å®ƒåªç”¨ä¸€ä¸ªé€»è¾‘åç§° tcp-echo-server æ¥ä»£è¡¨"è¿™é‡Œéœ€è¦ä¸€ä¸ª TCP Echo çš„é•œåƒ"ã€‚
# 2. çµæ´»æ€§ (Flexibility):
#    - Development ç¯å¢ƒï¼šå¯ä»¥å°† tcp-echo-server æ›¿æ¢ä¸º iceymoss/tcp-echo:dev
#    - Production ç¯å¢ƒï¼šå¯ä»¥å°† tcp-echo-server æ›¿æ¢ä¸º registry.company.com/stable/tcp-echo:v1.0.0
# 3. Base å±‚ï¼šæ°¸è¿œä¿æŒå¹²å‡€ï¼Œæ²¡æœ‰ä»»ä½•ç‰¹å®šçš„é•œåƒä»“åº“ä¾èµ–ã€‚
images:
  - name: tcp-echo-server    # [é‡ç‚¹] è¿™é‡Œå¿…é¡»å¡« Base é‡ŒåŸæœ¬å†™çš„é‚£ä¸ªé•œåƒå ä½ç¬¦åç§°ï¼
    newName: iceymoss/tcp-echo # æ›¿æ¢å¯¹åº”çš„é•œåƒä»“åº“å’Œåç§°
    newTag: "1.0"             # æ›¿æ¢ Tag
```

**å…³é”®çŸ¥è¯†ç‚¹**:

1. **Patches çš„ target å†™æ³•**:
   - **æ™®é€šèµ„æº**ï¼ˆDeployment/Serviceï¼‰ï¼šå†™ `kind` + `name` å³å¯
   - **CRD èµ„æº**ï¼ˆTraefik/CertManager/Prometheusï¼‰ï¼šä¿é™©èµ·è§ï¼Œä¸€å®šè¦å†™å…¨ `group` + `version` + `kind` + `name`

2. **é•œåƒæ›¿æ¢é€»è¾‘**:
   - `name`: å¿…é¡»å¡« Base é‡ŒåŸæœ¬å†™çš„é•œåƒå ä½ç¬¦åç§°ï¼ˆå¦‚ `tcp-echo-server`ï¼‰ï¼Œä¸æ˜¯å®¹å™¨å
   - `newName`: æ›¿æ¢æˆæ–°çš„é•œåƒä»“åº“å’Œåç§°
   - `newTag`: æ›¿æ¢æˆæ–°çš„æ ‡ç­¾

3. **æ›¿æ¢æµç¨‹**:
   ```
   Base: image: tcp-echo-server
   â†“
   Overlay: name: tcp-echo-server, newName: iceymoss/tcp-echo, newTag: "1.0"
   â†“
   æœ€ç»ˆ: image: iceymoss/tcp-echo:1.0
   ```

---

## 5. Multi-TCP Service Architecture Solutions

### 5.1 Problem Background

å½“ä½ åœ¨ `apps/backend` ä¸‹é™¤äº† `tcp-demo`ï¼Œè¿˜æœ‰å¤šä¸ª TCP æœåŠ¡æ—¶ï¼Œåº”è¯¥å¦‚ä½•é…ç½®ï¼Ÿ

**æ ¸å¿ƒé—®é¢˜**: å¯¹äºçº¯ TCPï¼ˆé TLS åŠ å¯†ï¼‰çš„æœåŠ¡ï¼Œä½ æ— æ³•åœ¨åŒä¸€ä¸ªç«¯å£ï¼ˆæ¯”å¦‚ 30999ï¼‰ä¸Šè¿è¡Œå¤šä¸ªä¸åŒçš„æœåŠ¡ã€‚

### 5.2 HTTP vs TCP Routing Differences

#### HTTP (Layer 7) - Can Share Ports

- æµé‡é‡ŒåŒ…å« `Host Header`ï¼ˆæ¯”å¦‚ `Host: a.com` å’Œ `Host: b.com`ï¼‰
- Traefik è¯»å–è¿™ä¸ª Headerï¼Œç„¶ååƒé‚®é€’å‘˜ä¸€æ ·æŠŠä¿¡åˆ†å‘ç»™ä¸åŒçš„äºº
- **ç»“è®º**: æˆåƒä¸Šä¸‡ä¸ª Web æœåŠ¡å¯ä»¥å…±ç”¨ä¸€ä¸ª 80 ç«¯å£

#### Pure TCP (Layer 4) - Cannot Share Ports

- æµé‡å°±æ˜¯ä¸€å †äºŒè¿›åˆ¶æ•°æ®æµï¼Œæ²¡æœ‰ Header
- Traefik å°±åƒé¢å¯¹ä¸¤ä¸ªè’™é¢äººï¼Œå®Œå…¨ä¸çŸ¥é“è°æ˜¯è°
- æ‰€ä»¥åœ¨é…ç½®é‡Œæˆ‘ä»¬è¢«è¿«å†™äº† `HostSNI('*')`ï¼ˆæ„æ€æ˜¯ï¼šåªè¦æ˜¯è¿™ä¸ªç«¯å£è¿›æ¥çš„ï¼Œä¸ç®¡æ˜¯è°ï¼Œå…¨é€èµ°ï¼‰
- **ç»“è®º**: ä¸€ä¸ªç«¯å£åªèƒ½è¢«ä¸€ä¸ªæœåŠ¡ç‹¬å 

### 5.3 Solution A: Multi-Port Strategy (Recommended)

This is the most commonly used and recommended solution. If you want to add a Redis service, you need to open another door on Traefik.

#### 5.3.1 Configuration Example

å‡è®¾ï¼š
- `tcp-demo` ç”¨ `30999` (NodePort) -> `9999` (Traefik)
- `redis-demo` ç”¨ `30379` (NodePort) -> `6379` (Traefik)

**ä¿®æ”¹ Traefik é…ç½®** (`argocd-bootstrap/ingress-controller/traefik-app.yaml`):

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: traefik-ingress
  namespace: argocd
spec:
  project: default
  source:
    chart: traefik
    repoURL: https://traefik.github.io/charts
    targetRevision: 26.0.0
    helm:
      values: |
        # ... å…¶ä»–é…ç½® ...

        # 1. å¢åŠ æ–°çš„ç›‘å¬ç«¯å£ (EntryPoint)
        additionalArguments:
          - "--accesslog=true"
          - "--accesslog.format=json"
          - "--entrypoints.mytcp.address=:9999/tcp"  # æ—§çš„ tcp-demo
          - "--entrypoints.redis.address=:6379/tcp"   # ã€æ–°å¢ã€‘ç»™ Redis å¼€ä¸ªé—¨

        # ... 

        # 2. æš´éœ²æ–°çš„ NodePort
        service:
          type: NodePort
        ports:
          # ... web/websecure ...

          # æ—§çš„ tcp-demo
          mytcp:
            port: 9999
            expose: true
            exposedPort: 9999
            protocol: TCP
            nodePort: 30999

          # ã€æ–°å¢ã€‘Redis ä¸“ç”¨ç«¯å£
          redis:
            port: 6379
            expose: true
            exposedPort: 6379
            protocol: TCP
            nodePort: 30379   # å¤–ç½‘é€šè¿‡è¿™ä¸ªç«¯å£è®¿é—® Redis
```

#### 5.3.2 Corresponding IngressRouteTCP Configuration

**Redis Service IngressRouteTCP** (`apps/backend/redis-demo/base/ingress-route-tcp.yaml`):

```yaml
apiVersion: traefik.io/v1alpha1
kind: IngressRouteTCP
metadata:
  name: redis-route
  namespace: backend
spec:
  entryPoints:
    - redis  # <--- ç»‘å®šåˆ°æ–°å¼€çš„å…¥å£
  routes:
    - match: HostSNI(`*`)
      services:
        - name: redis-service
          port: 6379
```

### 5.4 Solution B: TLS SNI Multiplexing (Advanced)

If your TCP service supports TLS encryption (i.e., the client and server perform SSL handshake), then Traefik can distinguish traffic through SNI (Server Name Indication).

In this case, you can let multiple TCP services share the same port (usually reuse 443).

#### 5.4.1 Usage Conditions

- å®¢æˆ·ç«¯è¿æ¥æ—¶å¿…é¡»ä½¿ç”¨ TLS
- å®¢æˆ·ç«¯å¿…é¡»å‘é€ SNI åŸŸåï¼ˆæ¯”å¦‚ `db.example.com`ï¼‰

#### 5.4.2 Configuration Example

**TCP Service A (DB)**:

```yaml
apiVersion: traefik.io/v1alpha1
kind: IngressRouteTCP
metadata:
  name: db-route
  namespace: backend
spec:
  entryPoints:
    - websecure  # å¤ç”¨ 443 ç«¯å£
  routes:
    - match: HostSNI(`db.example.com`) # <--- é åŸŸååŒºåˆ†ï¼
      services:
        - name: db-service
          port: 5432
  tls: # å¿…é¡»å¼€å¯ TLS
    passthrough: true # æˆ–è€… terminate
```

**TCP Service B (Cache)**:

```yaml
apiVersion: traefik.io/v1alpha1
kind: IngressRouteTCP
metadata:
  name: cache-route
  namespace: backend
spec:
  entryPoints:
    - websecure # ä¹Ÿæ˜¯ 443 ç«¯å£
  routes:
    - match: HostSNI(`cache.example.com`) # <--- é åŸŸååŒºåˆ†ï¼
      services:
        - name: cache-service
          port: 6379
  tls:
    passthrough: true
```

### 5.5 Solution Selection Recommendations

| Scenario | Recommended Solution | Reason |
|----------|---------------------|--------|
| Internal TCP services (databases, middleware, custom TCP protocols) | Solution A (Multi-Port Strategy) | Most stable, does not require client code changes to support TLS |
| Go programs (echo-server) without TLS handshake logic | Solution A | Simple and direct, no certificate handling needed |
| MySQL, Redis, MongoDB and other internal services | Solution A | Usually run internally, no encryption needed |
| TCP services exposed to public network and must be encrypted | Solution B | Security requirements |
| Extremely limited port resources (firewall only opens 443) | Solution B | Port limitations |

**Summary**: For the vast majority of internal TCP services, use Solution A (Multi-Port Strategy). Although it requires opening multiple ports, it is the most stable, does not require client code changes to support TLS, and does not need to handle complex certificate issues.

---

## 6. Best Practices

### 6.1 Directory Structure Standards

- **Base å±‚**: åªåŒ…å«é€šç”¨é…ç½®ï¼Œä¸åŒ…å«ç¯å¢ƒç‰¹å®šä¿¡æ¯
- **Overlay å±‚**: åŒ…å«ç¯å¢ƒå·®å¼‚åŒ–é…ç½®ï¼ˆèµ„æºé™åˆ¶ã€å‰¯æœ¬æ•°ã€é•œåƒæ ‡ç­¾ç­‰ï¼‰
- **å‘½åè§„èŒƒ**: ä¿æŒä¸ `hello-api` ç­‰ HTTP æœåŠ¡ä¸€è‡´çš„ç»“æ„

### 6.2 Image Management

- **å ä½ç¬¦æ¨¡å¼**: Base ä¸­ä½¿ç”¨é€»è¾‘åç§°ï¼ˆå¦‚ `tcp-echo-server`ï¼‰
- **ç¯å¢ƒéš”ç¦»**: ä¸åŒç¯å¢ƒä½¿ç”¨ä¸åŒçš„é•œåƒæ ‡ç­¾
- **è§£è€¦è®¾è®¡**: Base å±‚ä¸ä¾èµ–å…·ä½“é•œåƒä»“åº“

### 6.3 Resource Limits

- **å¼€å‘ç¯å¢ƒ**: è®¾ç½®è¾ƒå°çš„ Limitsï¼Œé˜²æ­¢ Bug ä»£ç åƒå…‰é›†ç¾¤èµ„æº
- **ç”Ÿäº§ç¯å¢ƒ**: Requests è®¾ç½®å¾—é«˜ä¸€ç‚¹ï¼ˆé¢„ç•™è¶³å¤Ÿèµ„æºï¼‰ï¼ŒLimits ä¹Ÿä¼šæ”¾å®½
- **QoS ç­‰çº§**: ç”Ÿäº§ç¯å¢ƒå¯ä»¥è®© Requests == Limits (QoS Class: Guaranteed) æ¥è·å¾—æœ€é«˜çš„ç¨³å®šæ€§

### 6.4 TCP Routing Configuration

- **EntryPoint å‘½å**: ä½¿ç”¨æœ‰æ„ä¹‰çš„åç§°ï¼ˆå¦‚ `mytcp`, `redis`, `mysql`ï¼‰
- **ç«¯å£è§„åˆ’**: æå‰è§„åˆ’å¥½ç«¯å£åˆ†é…ï¼Œé¿å…å†²çª
- **æ–‡æ¡£è®°å½•**: åœ¨æ–‡æ¡£ä¸­è®°å½•æ¯ä¸ª TCP æœåŠ¡ä½¿ç”¨çš„ç«¯å£å’Œ EntryPoint

### 6.5 Multi-Service Management

- **ç«¯å£åˆ†é…è¡¨**: ç»´æŠ¤ä¸€ä¸ªç«¯å£åˆ†é…è¡¨ï¼Œè®°å½•æ¯ä¸ªæœåŠ¡ä½¿ç”¨çš„ç«¯å£
- **ç»Ÿä¸€é…ç½®**: åœ¨ Traefik é…ç½®ä¸­ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ EntryPoint
- **å‘½åè§„èŒƒ**: ä½¿ç”¨ä¸€è‡´çš„å‘½åè§„èŒƒï¼ˆå¦‚ `{service-name}-route`ï¼‰

---

## Appendix

### A. Port Allocation Example Table

| æœåŠ¡åç§° | EntryPoint | Traefik ç«¯å£ | NodePort | ç”¨é€” |
|---------|-----------|-------------|----------|------|
| tcp-demo | mytcp | 9999 | 30999 | TCP Echo æœåŠ¡ |
| redis-demo | redis | 6379 | 30379 | Redis æœåŠ¡ |
| mysql-demo | mysql | 3306 | 30306 | MySQL æœåŠ¡ |

### B. Common Commands

```bash
# æŸ¥çœ‹æ‰€æœ‰ IngressRouteTCP
kubectl get ingressroutetcp -A

# æŸ¥çœ‹ Traefik EntryPoints
kubectl logs -n traefik -l app.kubernetes.io/name=traefik | grep entrypoint

# æµ‹è¯• TCP è¿æ¥
nc -zv <NodeIP> <NodePort>

# æŸ¥çœ‹ Service Endpoints
kubectl get endpoints -n backend
```

### C. Reference Resources

- [Kustomize å®˜æ–¹æ–‡æ¡£](https://kustomize.io/)
- [Traefik IngressRouteTCP æ–‡æ¡£](https://doc.traefik.io/traefik/routing/providers/kubernetes-crd/#kind-ingressroutetcp)
- [Kubernetes Service æ–‡æ¡£](https://kubernetes.io/docs/concepts/services-networking/service/)

---

**æ–‡æ¡£ç»´æŠ¤**: æœ¬æ–‡æ¡£åº”éšé¡¹ç›®é…ç½®æ›´æ–°åŠæ—¶æ›´æ–°ã€‚  
**æœ€åæ›´æ–°**: 2025-12-25

